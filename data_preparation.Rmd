---
title: "COVID-19 data preparation"
author: "Sven Lautenbach"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    gallery: TRUE
    lightbox: TRUE
    thumbnails: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(rmdformats)
require(tidyverse)
require(ggplot2)
require(lubridate)
require(sf)
require(zoo)
require(spdep)
require(tmap)
require(tidyquant)
require(readODS)
```

# Data acquisition

-   COVID 19 case data by RKI, manual download and metadata here: <https://www.arcgis.com/home/item.html?id=f10774f1c63e40168479a1feb6c7ca74>

-   Kreis (counties or districts) boundaries with population counts, manual download and metadata here:\
    <https://gdz.bkg.bund.de/index.php/default/verwaltungsgebiete-1-250-000-mit-einwohnerzahlen-ebenen-stand-31-12-vg250-ew-ebenen-31-12.html>

The following code-chunk will check if the data is already downloaded and for the COVID cases data check if it's up-to-date.

```{r}
# create folder structure
if (!dir.exists("data/")) {
  dir.create("data/", recursive = T)
}

options(timeout = 1080) # avoid download cut-off at 60sec

# check if RKI case data is downloaded/the latest state
if (as.Date(Sys.time()) - as.Date(file.info("data/RKI_COVID19.csv")$ctime) > 0 | is.na(as.Date(Sys.time()) - as.Date(file.info("data/RKI_COVID19.csv")$ctime))) {
  download.file(
    "https://www.arcgis.com/sharing/rest/content/items/f10774f1c63e40168479a1feb6c7ca74/data",
    destfile = "data/RKI_COVID19.csv",
    mode = 'wb'
  )
}

```

Meta-data: https://www.arcgis.com/home/item.html?id=f10774f1c63e40168479a1feb6c7ca74

```{r}
dat <- read.table("data/RKI_COVID19.csv", header=TRUE, sep=",")
```

```{r, eval=T}
# check if Kreis boundaries are downloaded, if not, do it
if (!file.exists("data/vg250-ew_12-31.utm32s.shape.ebenen/vg250-ew_ebenen_1231/VG250_KRS.shp")) {
  download.file(
    "https://daten.gdz.bkg.bund.de/produkte/vg/vg250-ew_ebenen_1231/aktuell/vg250-ew_12-31.utm32s.shape.ebenen.zip",
    destfile = "data/vg250-ew_12-31.utm32s.shape.ebenen.zip",
    mode = 'wb'
  )
  unzip(zipfile = "data/vg250-ew_12-31.utm32s.shape.ebenen.zip",
        exdir = "data/")
}
```

# Explore COVID Case Data


```{r}
summary(dat)
```

The COVID 19 dataset is `r ncol(dat)` attributes/columns wide and `r nrow(dat)` long.


Extract Bundesland (federal state NUTS1) to Kreis (district, NUTS3) relationship

```{r}
Landkreis2Land <- dplyr::select(dat, IdLandkreis, Landkreis, Bundesland) %>%
  group_by(IdLandkreis) %>% summarise(Landkreis = first(Landkreis) ,Bundesland = first(Bundesland))
Landkreis2Land$IdLandkreis_char <- as.character(Landkreis2Land$IdLandkreis)
```

A total of `r nrow(Landkreis2Land)` are in our dataset.

## Temporal dimension

Next, we dig into the timeseries component of the data. Therefore we check and convert the date attribute.


```{r}
head(dat$Meldedatum)
tail(dat$Meldedatum)
```

Events reported at resolution of days.

```{r}
# get unique dates
unique_dates <- length(unique(dat$Refdatum))
# check COVID file date
time_diff <- max(ymd_hms(dat$Refdatum)) - min(ymd_hms(dat$Refdatum))
time_diff
```

The data set includes `r unique_dates` unique dates. Time range across all records is `r time_diff`. Therefore we can conclude there are no duplicates.

```{r}
# convert to date datatype
dat$Refdatum <- ymd_hms(dat$Refdatum)
dat$Meldedatum <- ymd_hms(dat$Meldedatum)
```

## Cases

Let's have a look at one Landkreis and check how many records exist per day.

```{r}
plot(xtabs( ~ Refdatum, data = dat %>% dplyr::filter(Landkreis == "SK Kiel")),
     xlab = "Time in days (RefDatum)",
     ylab = "Amount of events")
```

```{r}
# filter data for Kiel and a specific date with several reportings
dat %>% 
  dplyr::filter(Landkreis == "SK Kiel" & Refdatum == ymd("2020-12-01")) %>%
  head()
```

We see multiple events per day and Landkreis. This is due to further grouping variables like age groups and gender, but also due to lags in reporting cases.

```{r}
dat %>% 
  dplyr::filter(AnzahlFall < 0) %>% 
  head()

```

Negative case reporting at a later date is possible and needs to be accounted for.

# Aggregation by date of infection

Aggregate counts over all age groups and gender

```{r}
datAgg <- dat %>% group_by(IdLandkreis,  Refdatum) %>%
  summarize(sumCount = sum(AnzahlFall, na.rm = TRUE), 
            sumDeath = sum(AnzahlTodesfall, na.rm = TRUE),
            Landkreis = first(Landkreis) ,Bundesland = first(Bundesland))
```

```{r}
summary(datAgg)
```

The -1 is due to that the case had been reported at the day before.

```{r}
complete_ts <- length(unique(datAgg$Refdatum)) * length(unique(datAgg$IdLandkreis))
miss_ts <- length(unique(datAgg$Refdatum)) * length(unique(datAgg$IdLandkreis)) -  nrow(datAgg)
```

A complete timeseries would have `r (length(unique(datAgg$Refdatum)) * length(unique(datAgg$IdLandkreis)))` records. Our dataset is `r miss_ts` short, e.g. a district did not report. For those we need to fill in zeros.

```{r}
plot(xtabs(~ Bundesland, datAgg),
     xlab = "Bundesland",
     ylab = "Amount of events")
```


## Complete timeseries

Make a wide tibble where every record represents a date and every column the sum of cases in a Kreis. First sort by date. Then we replace the NAs in the Kreis columns for the dates with no observations. Afterwards we change to a long tibble in which every record is a Kreis and every column is the sum of cases on a date.

```{r}
# wide tibble with dates as records and Landkreise as columns
datAggCases_wideByDistrict <-
  arrange(datAgg, Refdatum, .by_group = TRUE) %>%
  pivot_wider(names_from = IdLandkreis,
              values_from = sumCount,
              id_cols = Refdatum)
```

```{r}
# long tibble with dates and Landkreise as single records and one case column
datAggCases_long <-
  pivot_longer(datAggCases_wideByDistrict,
               cols = -Refdatum,
               names_to = "IdLandkreis")
```

Replace NA with zeros and join the name of Landkreis and Bundesland.

```{r}
# Replace NA with zeros
datAggCases_long$sumCount <-
  replace_na(datAggCases_long$value, replace = 0)
# join long tibble name of Landkreis and Bundesland
datAggCases_long <-
  left_join(datAggCases_long,
            Landkreis2Land,
            by = c("IdLandkreis" = "IdLandkreis_char")) %>%
  dplyr::select(-c(IdLandkreis.y, value)) # remove duplicate attribute and not needed value attr 
```



```{r, fig.width=11, fig.height=12}
ggplot(datAggCases_long, aes(x=Refdatum, y= sumCount, colour=factor(IdLandkreis))) +
  geom_line(show.legend = FALSE) + facet_wrap(~Bundesland)
```

## Aggregation to 7 day incidence

In order to minimize noise from daily reporting, we will now aggregate our data to 7 day incidence rolling mean and sum. We also add the R0 reproduction value. The calculation is based on <https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Projekte_RKI/R-Wert-Erlaeuterung.pdf?__blob=publicationFile>

```{r}
datAggCases_long <- datAggCases_long %>% group_by(IdLandkreis) %>%
  arrange(Refdatum) %>%
  summarise(
    sumCountRollMean7 = rollapply(
      sumCount,
      width = 7,
      FUN = mean,
      na.rm = TRUE,
      fill = NA
    ),
    sumCountSum7 = rollapply(
      sumCount,
      width = 7,
      FUN = sum,
      align = "right",
      partial = FALSE,
      fill = NA,
      na.rm = TRUE
    ),
    # first 7day window of i+1:i-5
    sumOverlap1 = rollapply( 
      sumCount,
      width = list(1:-5),
      FUN = sum,
      align = "right",
      partial = FALSE,
      fill = NA,
      na.rm = TRUE
    ),
    # second 7day window of i-3:i-9
    sumOverlap2 = rollapply(
      sumCount,
      width = list(-3:-9),
      FUN = sum,
      align = "right",
      partial = FALSE,
      fill = NA,
      na.rm = TRUE
    ),
    Refdatum = Refdatum
  ) %>%
  mutate(R0_7 = case_when(
    is.infinite(round(sumOverlap1 / sumOverlap2, digits = 4)) == TRUE ~ as.numeric(NA),
    TRUE ~ round(sumOverlap1 / sumOverlap2, digits = 4)
  )) %>%
  left_join(datAggCases_long, by = c("IdLandkreis", "Refdatum")) %>%  
  dplyr::select(-c(sumOverlap1, sumOverlap2))
```

Visualization as plots

```{r, warning=FALSE,  fig.width=11, fig.height=12}
ggplot(datAggCases_long,
       aes(
         x = Refdatum,
         y = sumCountRollMean7,
         colour = factor(IdLandkreis)
       )) +
  geom_line(show.legend = FALSE) + facet_wrap( ~ Bundesland) + theme_light() +
  ylab("7-day rolling mean") + xlab("Reference date")

ggplot(datAggCases_long,
       aes(
         x = Refdatum,
         y = sumCountSum7,
         colour = factor(IdLandkreis)
       )) +
  geom_line(show.legend = FALSE) + facet_wrap( ~ Bundesland) +
  ylab("7-day mean") + xlab("Reference date")

ggplot(datAggCases_long,
       aes(
         x = Refdatum,
         y = R0_7,
         colour = factor(IdLandkreis)
       )) +
  geom_line(show.legend = FALSE) + facet_wrap( ~ Bundesland)+
  ylab("7-day R0") + xlab("Reference date")
```


## Link to spatial data

Now we want to link the COVID 19 case data onto the spatial boundaries of each Kreis.

```{r, eval = T}
# load spatial boundaries for kreise (county or district)
kreiseSf <-
  st_read("data/vg250-ew_12-31.utm32s.shape.ebenen/vg250-ew_ebenen_1231/VG250_KRS.shp")
```


The attribute ARS from the spatial dataset can be linked to IdLandkreis from the COVID 19 dataset

```{r}
length(unique(kreiseSf$ARS))
length(unique(datAgg$IdLandkreis))
head(unique(kreiseSf$ARS))
head(unique(datAgg$IdLandkreis))
```

We see a difference of 10 Kreise which are not present in the spatial data set. We keep that in mind. First we change the setup of our COVID 19 tibble to a wide format with every row representing one Kreis and every reporting day as attribute/column. Also we need to add a 0 on every Landkreise Id.

Actually the problems come from two sources:

  - Eisenach and the Wartburgkreis have been merged at first of July 2021. The administrative boundaries do not reflect this. We will dissolve the two units into one. The INKAR official statistics are reported still at the old level. Therefore, we have pre-processed theses data already ahead of time.
  - Berlin is reported at a finer scale by the RKI data when the administrative units and the INKAR statistics. For shortage of time we are aggregating the different districts for Berlin here.
  
Dissolve Eisenach and Wartburgkreis:

```{r}
filter(kreiseSf, GEN %in% c("Eisenach", "Wartburgkreis")) %>% plot(max.plot = 1)
```

Add a dummy field that contains everywhere distinct values but not for the two districts if interest:

```{r}
idx <- which(kreiseSf$GEN %in% c("Eisenach", "Wartburgkreis"))
kreiseSf$dummy <- 1:nrow(kreiseSf)
kreiseSf$dummy[idx] <- 0
```

Dissolve by dummy field and recalculate attribute fields. As Eisenach comes first we use *last* to get the different identifiers from Wartburgkreis. For the inhabitants (EWZ) we have to sum the two values.

```{r}
#head(kreiseSf)
kreiseSfDissolved <- kreiseSf %>% group_by(dummy) %>% 
  summarize(RS_0 = last(RS_0), EWZ = sum(EWZ), 
            GEN = last(GEN), GF = last(GF), BEZ = last(BEZ),
            ADE = last (ADE), BSG = last(BSG), ARS = last(ARS),
            AGS = last(ARS), SDV_ARS = last(SDV_ARS),
            ARS_0 = last(ARS_0), AGS_0 = last(AGS_0), RS = last(RS))
```


```{r}
kreiseSfDissolved %>% 
  dplyr::filter(GEN %in% c("Eisenach", "Wartburgkreis"))
```

Drop the dummy field

```{r}
kreiseSfDissolved$dummy <- NULL
```

```{r}
kreiseSf <- kreiseSfDissolved
```


```{r}
datAgg_wide <-
  arrange(datAggCases_long, Refdatum, .by_group = TRUE) %>%
  pivot_wider(
    id_cols = IdLandkreis,
    names_from = Refdatum,
    values_from = c(sumCountSum7),
    names_prefix = "cases7days_"
  )
head(datAgg_wide)
dim(datAgg_wide)
```

Check which columns show NAs only.

```{r}
#apply(datAgg_wide, MARGIN = 2, FUN = function(x) length(which(is.na(x))))
idx_na <- which(is.na(datAgg_wide), arr.ind = TRUE)
unique(names(datAgg_wide)[idx_na[,2]])
#datAgg_wide <- replace_na(datAgg_wide, replace = 0)
```

Only the first couple of days in the data set are filled with NAs. Next we join the case data onto the spatial boundaries.

```{r}
# convert to string format
datAgg_wide$IdLandkreis_char <-
  as.character(datAgg_wide$IdLandkreis)
# add 0 to every Landkreise Id
datAgg_wide$IdLandkreis_char <-
  str_pad(
    datAgg_wide$IdLandkreis_char,
    width = 5,
    side = "left",
    pad = "0"
  )

kreiseSf %>% filter(is.na(match(
  kreiseSf$ARS, datAgg_wide$IdLandkreis_char
)) == T)
```

We see a problem with Berlin.

```{r}
Landkreis2Land %>% dplyr::filter(str_detect(Landkreis, "Berlin"))
kreiseSf %>% dplyr::filter(str_detect(GEN, "Berlin"))
```

Several districts for Berlin which are not in the geodata - we need to aggregate the data.

```{r}
idx_berlin <- which(Landkreis2Land$Bundesland == "Berlin")
idx_berlinInRKI <-
  which(datAgg_wide$IdLandkreis %in% Landkreis2Land$IdLandkreis[idx_berlin])

incidenceFieldsIdxRki <-
  grep(pattern = "cases7days_", x = names(datAgg_wide))

# add the data as a new row
n <- nrow(datAgg_wide)

sumCases4Berlin <-
  apply(
    datAgg_wide[idx_berlinInRKI, incidenceFieldsIdxRki],
    MARGIN = 2,
    FUN = function(x)
      sum(x, na.rm = TRUE)
  )
datAgg_wide[n + 1, ] <- rep(NA, n = ncol(datAgg_wide))
datAgg_wide[n + 1, 1] <-
  "11000" #c(11000, t(as.numeric(sumCases4Berlin)), "11000")
datAgg_wide[n + 1, 2:(ncol(datAgg_wide) - 1)] <-
  t(as.numeric(sumCases4Berlin))
datAgg_wide[n + 1, ncol(datAgg_wide)] <- "11000"

# drop the bezirke of berlin from the tibble to avoid double counting later on
datAgg_wide <- datAgg_wide[-idx_berlinInRKI, ]
```

Add Berlin to the Landkreis- Bundesland relationship table as well.

```{r}
Landkreis2Land[nrow(Landkreis2Land)+1, ] <- list(IdLandkreis = 11000, Landkreis = "Berlin", Bundesland = "Berlin", IdLandkreis_char = "11000")
```

Finally, we join the covid-19 case data to the pre-processed spatial data set and ensure proper and understandable field names.

```{r}
kreiseWithCovid <- left_join(kreiseSf, datAgg_wide, by= c("ARS" = "IdLandkreis_char"))

# ensure proper field names
incidenceFieldsIdxKreise <-
  grep(pattern = "cases7days_", x = names(kreiseWithCovid))

names(kreiseWithCovid)[incidenceFieldsIdxKreise] <-
  gsub(pattern = "-",
       replacement = "_",
       names(kreiseWithCovid)[incidenceFieldsIdxKreise])
```


## Test maps

Districts without inhabitants

```{r}
#idx0ew <- which(kreiseWithCovid$EWZ == 0)
kreiseWithCovid %>% filter( EWZ == 0) %>% dplyr::select(ADE:AGS_0)

kreiseWithCovid$noEWZ <- ifelse(kreiseWithCovid$EWZ == 0, 1, 0)
```

```{r}
kreiseWithCovid %>% dplyr::filter( EWZ == 0) %>%
tm_shape() + tm_polygons(col="noEWZ", n=2) +
  tm_layout(legend.outside = TRUE)
```

These are all GF==2 areas, i.e. water bodies and other uninhabited regions

Drop those:

```{r}
kreiseWithCovidCleaned <- dplyr::filter(kreiseWithCovid, GF !=2)
```

Lets create a map of the incidence rate for a specific week

```{r}
breaks = c(0, 5,25,50, 100,250,500, 1000)
kreiseWithCovidCleaned %>% mutate(incidence_rate = cases7days_2021_09_27 / EWZ * 10^5 ) %>%
tm_shape() + tm_polygons(col="incidence_rate", breaks= breaks, title = "Incidence rate") +
  tm_layout(legend.outside = TRUE, main.title = "Week of 27th September 2021")
```


# Aggregate by Meldedatum

Actually these seem to be the numbers in the official maps provided by the RKI.  Lets redo the steps but for the Meldedatum attribute.


```{r}
datAggMelde <- dat %>% group_by(IdLandkreis,  Meldedatum) %>%
  summarize(sumCount = sum(AnzahlFall, na.rm = TRUE), 
            sumDeath = sum(AnzahlTodesfall, na.rm = TRUE),
            Landkreis = first(Landkreis) ,Bundesland = first(Bundesland))
```

```{r}
datAggCasesMelde_wideByDistrict <- arrange(datAggMelde, Meldedatum, .by_group = TRUE) %>% 
  pivot_wider( names_from = IdLandkreis, values_from = sumCount, id_cols = Meldedatum)
```


```{r}
datAggCasesMelde_long <- pivot_longer(datAggCasesMelde_wideByDistrict, cols = -Meldedatum, names_to = "IdLandkreis")
```


Replace NA with zeros

```{r}
datAggCasesMelde_long$sumCount <- replace_na(datAggCasesMelde_long$value, replace = 0)
datAggCasesMelde_long <- left_join(datAggCasesMelde_long, Landkreis2Land, by= c("IdLandkreis" = "IdLandkreis_char"))
```


```{r, fig.width=11, fig.height=12}
ggplot(datAggCasesMelde_long, aes(x=Meldedatum, y= sumCount, colour=factor(IdLandkreis))) +
  geom_line(show.legend = FALSE) + facet_wrap(~Bundesland)
```

## 7-day rolling mean and 7-day sum

```{r}
datAggCasesMelde_long <-
  datAggCasesMelde_long %>% group_by(IdLandkreis) %>%
  summarise(
    sumCountRollMean7 = rollapply(
      sumCount,
      width = 7,
      FUN = mean,
      na.rm = TRUE,
      fill = NA
    ),
    sumCountSum7 = rollapply(
      sumCount,
      width = 7,
      FUN = sum,
      align = "right",
      partial = FALSE,
      fill = NA,
      na.rm = TRUE
    ),
    # first 7day window of i+1:i-5
    sumOverlap1 = rollapply( 
      sumCount,
      width = list(1:-5),
      FUN = sum,
      align = "right",
      partial = FALSE,
      fill = NA,
      na.rm = TRUE
    ),
    # second 7day window of i-3:i-9
    sumOverlap2 = rollapply(
      sumCount,
      width = list(-3:-9),
      FUN = sum,
      align = "right",
      partial = FALSE,
      fill = NA,
      na.rm = TRUE
    ),
    Meldedatum = Meldedatum
  ) %>%
  mutate(R0_7 = case_when(
    is.infinite(round(sumOverlap1 / sumOverlap2, digits = 4)) == TRUE ~ as.numeric(NA),
    TRUE ~ round(sumOverlap1 / sumOverlap2, digits = 4)
  )) %>%
  left_join(datAggCasesMelde_long, by = c("IdLandkreis", "Meldedatum")) %>% 
  dplyr::select(-c(sumOverlap1, sumOverlap2))
```


## Join with spatial data

Bring to wide format

```{r}
datAggMelde_wide <- arrange(datAggCasesMelde_long, Meldedatum, .by_group = TRUE) %>%  
  pivot_wider( id_cols = IdLandkreis, names_from = Meldedatum, 
               values_from = sumCountSum7, names_prefix = "cases7days_")
```

```{r}
datAggMelde_wide$IdLandkreis_char <- as.character(datAggMelde_wide$IdLandkreis)
datAggMelde_wide$IdLandkreis_char <- str_pad(datAggMelde_wide$IdLandkreis_char, width=5, side="left", pad="0")


idx <- which(is.na(match(kreiseSf$ARS, datAggMelde_wide$IdLandkreis_char)))
kreiseSf[idx,]
```

```{r}
datAggMelde_wide$IdLandkreis_char <- as.character(datAggMelde_wide$IdLandkreis)
datAggMelde_wide$IdLandkreis_char <- str_pad(datAggMelde_wide$IdLandkreis_char, width=5, side="left", pad="0")

```

We see a problem with Berlin.

Several districts for Berlin which are not in the geodata - need to aggregate the data.

```{r}
idx_berlin <- which(Landkreis2Land$Bundesland == "Berlin")
idx_berlinInRKI <-
  which(datAggMelde_wide$IdLandkreis %in% Landkreis2Land$IdLandkreis[idx_berlin])

incidenceFieldsIdxRki <-
  grep(pattern = "cases7days_", x = names(datAggMelde_wide))

# add the data as a new row
n <- nrow(datAggMelde_wide)

sumCases4Berlin <-
  apply(
    datAggMelde_wide[idx_berlinInRKI, incidenceFieldsIdxRki],
    MARGIN = 2,
    FUN = function(x)
      sum(x, na.rm = TRUE)
  )
datAggMelde_wide[n + 1, ] <- rep(NA, n = ncol(datAggMelde_wide))
datAggMelde_wide[n + 1, 1] <-
  "11000" #c(11000, t(as.numeric(sumCases4Berlin)), "11000")
datAggMelde_wide[n + 1, 2:(ncol(datAggMelde_wide) - 1)] <-
  t(as.numeric(sumCases4Berlin))
datAggMelde_wide[n + 1, ncol(datAggMelde_wide)] <- "11000"

# drop the bezirke of berlin from the tibble to avoid double counting later on
datAggMelde_wide <- datAggMelde_wide[-idx_berlinInRKI, ]
```


```{r}
kreiseWithCovidMelde <-
  left_join(kreiseSf, datAggMelde_wide, by = c("ARS" = "IdLandkreis_char"))

# ensure proper field names
incidenceFieldsIdxKreise <-
  grep(pattern = "cases7days_", x = names(kreiseWithCovidMelde))
names(kreiseWithCovidMelde)[incidenceFieldsIdxKreise] <-
  gsub(pattern = "-",
       replacement = "_",
       names(kreiseWithCovidMelde)[incidenceFieldsIdxKreise])
```

Remove waterbodies again.

```{r}
kreiseWithCovidMeldeCleaned <- dplyr::filter(kreiseWithCovidMelde, GF != 2)
```

```{r}
breaks = c(0, 5,25,50, 100, 250, 500, 1000)
kreiseWithCovidMeldeCleaned %>% 
  mutate(incidence_rate = cases7days_2021_09_27 / EWZ * 10^5 ) %>%
  tm_shape() + 
  tm_polygons(col="incidence_rate", breaks= breaks,  legend.hist = TRUE, 
              palette= "-plasma", legend.reverse = TRUE, title = "Incidence rate") +
  tm_layout(legend.outside = TRUE, bg.color = "darkgrey", outer.bg.color = "lightgrey",
            legend.outside.size = 0.5, attr.outside = TRUE, 
            main.title = "Week of 27th September 2021") + tm_scale_bar()
```

### Aggregate for each calender week

```{r, warning = FALSE}
datAggCasesMeldeWeekly_long <-
  datAggCasesMelde_long %>% group_by(IdLandkreis) %>% tq_transmute(
    select = c("sumCount"),
    mutate_fun = apply.weekly,
    FUN        = sum,
    na.rm      = TRUE,
    col_rename = "sumCount_weekly"
  )
```

```{r}
datAggMeldeWeekly_wide <-
  arrange(datAggCasesMeldeWeekly_long, Meldedatum, .by_group = TRUE) %>%
  pivot_wider(
    id_cols = IdLandkreis,
    names_from = Meldedatum,
    values_from = sumCount_weekly,
    names_prefix = "casesWeek_"
  )
```

```{r}
datAggMeldeWeekly_wide$IdLandkreis_char <-
  as.character(datAggMeldeWeekly_wide$IdLandkreis)
datAggMeldeWeekly_wide$IdLandkreis_char <-
  str_pad(
    datAggMeldeWeekly_wide$IdLandkreis_char,
    width = 5,
    side = "left",
    pad = "0"
  )
```

Several districts for Berlin which are not in the geodata - need to aggregate the data.

```{r}
idx_berlin <- which(Landkreis2Land$Bundesland == "Berlin")
idx_berlinInRKI <-
  which(datAggMeldeWeekly_wide$IdLandkreis %in% Landkreis2Land$IdLandkreis[idx_berlin])

incidenceFieldsIdxRki <-
  grep(pattern = "casesWeek_", x = names(datAggMeldeWeekly_wide))

# add the data as a new row
n <- nrow(datAggMeldeWeekly_wide)

sumCases4Berlin <-
  apply(
    datAggMeldeWeekly_wide[idx_berlinInRKI, incidenceFieldsIdxRki],
    MARGIN = 2,
    FUN = function(x)
      sum(x, na.rm = TRUE)
  )
datAggMeldeWeekly_wide[n + 1, ] <-
  rep(NA, n = ncol(datAggMeldeWeekly_wide))
datAggMeldeWeekly_wide[n + 1, 1] <-
  "11000" #c(11000, t(as.numeric(sumCases4Berlin)), "11000")
datAggMeldeWeekly_wide[n + 1, 2:(ncol(datAggMeldeWeekly_wide) - 1)] <-
  t(as.numeric(sumCases4Berlin))
datAggMeldeWeekly_wide[n + 1, ncol(datAggMeldeWeekly_wide)] <-
  "11000"

# drop the bezirke of berlin from the tibble to avoid double counting later on
datAggMeldeWeekly_wide <- datAggMeldeWeekly_wide[-idx_berlinInRKI, ]
```

### Join spatial data

```{r}
kreiseWithCovidMeldeWeekly <-
  left_join(kreiseSf,
            datAggMeldeWeekly_wide,
            by = c("ARS" = "IdLandkreis_char"))

# ensure proper field names
incidenceFieldsIdxKreise <-
  grep(pattern = "casesWeek_",
       x = names(kreiseWithCovidMeldeWeekly))
names(kreiseWithCovidMeldeWeekly)[incidenceFieldsIdxKreise] <-
  gsub(pattern = "-",
       replacement = "_",
       names(kreiseWithCovidMeldeWeekly)[incidenceFieldsIdxKreise])
```

```{r}
kreiseWithCovidMeldeWeeklyCleaned <-
  filter(kreiseWithCovidMeldeWeekly, GF != 2)
```

```{r}
breaks = c(0, 5, 25, 50, 100, 250, 500, 1000)
kreiseWithCovidMeldeWeeklyCleaned %>% 
  mutate(incidence_rate = casesWeek_2021_09_26 / EWZ * 10 ^5) %>%
  tm_shape() + tm_polygons(
    col = "incidence_rate",
    breaks = breaks,
    legend.hist = TRUE,
    palette = "-plasma",
    legend.reverse = TRUE
  ) +
  tm_layout(
    legend.outside = TRUE,
    bg.color = "darkgrey",
    outer.bg.color = "lightgrey",
    legend.outside.size = 0.5,
    attr.outside = TRUE,
    main.title = "Week of 27th September 2021"
  ) + tm_scale_bar()
```

# Aggregate over whole period

```{r}
idxCaseFieldPosition <- grep(pattern = "casesWeek_", x = names(kreiseWithCovidMeldeWeeklyCleaned))
namesCaseFieldPosition <-  names(kreiseWithCovidMeldeWeeklyCleaned)[idxCaseFieldPosition]
```


```{r}
kreiseWithCovidMeldeWeeklyCleaned$sumCasesTotal <-
  apply(st_drop_geometry(kreiseWithCovidMeldeWeeklyCleaned[, idxCaseFieldPosition]), 
        MARGIN= 1, 
      FUN = function(x) sum(x, na.rm = TRUE))
```




```{r}
kreiseWithCovidMeldeWeeklyCleaned %>% 
  mutate(incidence_rate = sumCasesTotal / EWZ * 10^5 ) %>%
  tm_shape() + 
  tm_polygons(col="incidence_rate",   legend.hist = TRUE, palette= "-plasma",
                         legend.reverse = TRUE, title = "Incidence rate for total period") +
  tm_layout(legend.outside = TRUE, bg.color = "darkgrey", outer.bg.color = "lightgrey",
            legend.outside.size = 0.5, attr.outside = TRUE) + tm_scale_bar()
```

```{r}
kreiseWithCovidMeldeWeeklyCleaned$incidenceTotal <-  kreiseWithCovidMeldeWeeklyCleaned$sumCasesTotal / kreiseWithCovidMeldeWeeklyCleaned$EWZ * 10^5
```

```{r}
kreiseWithCovidMeldeWeeklyCleaned$casesWeek_2021_10_31
```


# Add covariates

Data needs to be downloaded from:

The data has been extracted from: https://www.inkar.de/
Meta-data is available at this page as well - unfortunately in German only. Field names are in German as well

```{r}
load("data/inkarKreisstatistik_preprocessed.Rdata", verbose=TRUE)
```

Join with the spatial data aggregated at weekly basis:

```{r}
kreiseWithCovidMeldeWeeklyCleanedPredictorsAdded <- left_join(kreiseWithCovidMeldeWeeklyCleaned, predictors2, by= c("RS_0" = "RS_0"))
```

## Serialize the data to disk

```{r}
save(kreiseWithCovidMeldeCleaned, file="data/kreiseWithCovidByMeldedatum.Rdata")
save(kreiseWithCovidCleaned, file="data/kreiseWithCovidByRefdatum.Rdata")
save(kreiseWithCovidMeldeWeeklyCleaned, file="data/kreiseWithCovidMeldedatumWeekly.Rdata")
save(kreiseWithCovidMeldeWeeklyCleanedPredictorsAdded, file="data/kreiseWithCovidMeldedatumWeeklyPredictors.Rdata")
```

If use in a geographic information system such as QGIS is desired data should be exported in a different format. Here we use the geopackage format.

```{r}
st_write(kreiseWithCovidMeldeWeeklyCleanedPredictorsAdded, 
         dsn = "../../data/covidKreise.gpkg", 
         layer = "kreiseWithCovidMeldeWeeklyCleaned", 
         delete_layer = TRUE)
```


## Aggregate per Week

```{r}
idxCaseFieldPosition <- grep(pattern = "casesWeek_", x = names(kreiseWithCovidMeldeWeeklyCleaned))
namesCaseFieldPosition <-  names(kreiseWithCovidMeldeWeeklyCleaned)[idxCaseFieldPosition]
# strip prefix
dateStrVec <- gsub(pattern = "casesWeek_", replacement = "", x = namesCaseFieldPosition)
```

Get the sum across all distrcits for each week

```{r}
totalPop <- sum(kreiseWithCovidMeldeWeeklyCleaned$EWZ)
```

```{r}
nationalAggCases <- data.frame(week = ymd(dateStrVec), cases = NA)
for(i in 1:length(dateStrVec))
{
  fieldName <- paste0("casesWeek_", dateStrVec[i])
  nationalAggCases$cases[i] <- sum(st_drop_geometry(kreiseWithCovidMeldeWeeklyCleaned)[, fieldName]) 
}
nationalAggCases$incidence <- nationalAggCases$cases / totalPop * 10^5
```


```{r}
save(nationalAggCases, file = "data/nationalAggCases.Rdata")
```

